{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cymon\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\cymon\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\\<indicate target task (i.e. classification or regression) here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "**`Music`** is a universal language, transcending cultures and time. It is a powerful art form that can evoke a wide range of emotions, from joy and excitement to sadness and reflection. Music can be used to express oneself, to connect with others, and to celebrate life. We are studying this dataset because it could be essential for studying music and developing new music technologies. In this notebook in particular, it will be used to train machine learning models to perform a variety of tasks. These models can then be used to create new products and services, such as personalized music streaming services and intelligent music assistants.\n",
    "\n",
    "The dataset is provided as a `.csv` file where it can be viewed in Excel and Notepad. \n",
    "\n",
    "This dataset contains 17,996 **rows** across 17 **columns**. Each row represents **1 song**, while columns represent **audio features**. The following are the columns in the dataset and their descriptions:\n",
    "\n",
    "| Column Name | Description |\n",
    "| --- | --- |\n",
    "| **`Artist Name`** | Name of artist |\n",
    "| **`Track Name`** | Name of song |\n",
    "| **`Popularity`** | A value between 0 and 100, calculated by an algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are |\n",
    "| **`danceability`** | Describes how suitable a track is for dancing; 0.0 is least danceable and 1.0 is most danceable |\n",
    "| **`energy`** | A measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity |\n",
    "| **`key`** | The key the track is in, integers map to pitches using standard [Pitch Class notation](https://en.wikipedia.org/wiki/Pitch_class); -1 if no key was detected |\n",
    "| **`loudness`** | The quality of a sound that is the primary psychological correlate of physical strength (amplitude), values are averaged across the entire track; in decibels (dB) |\n",
    "| **`mode`** | Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived; 1 is Major and 0 is Minor |\n",
    "| **`speechiness`** | The presence of spoken words in a track; >0.66 is probably made entirely of spoken words, 0.33-0.66 may contain both music and speech, <0.33 most likely represents music |\n",
    "| **`acousticness`** | A confidence measure from 0.0 to 1.0 of whether the track is acoustic |\n",
    "| **`instrumentalness`** | Predicts whether a track contains no vocals; >0.5 is intended to represent instrumental tracks |\n",
    "| **`liveness`** | Detects the presence of an audience in the recording; >0.8 provides strong likelihood that the track is live |\n",
    "| **`valence`** | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track; tracks with high valence sound more positive, and vice versa|\n",
    "| **`tempo`** | The overall estimated tempo of a track in beats per minute (BPM) |\n",
    "| **`duration_in min/ms`** | Duration in millisecond (ms) |\n",
    "| **`time_signature`** | A notational convention to specify how many beats are in each bar |\n",
    "| **`Class`** | corresponds to the genre of the track |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State a brief description of the dataset.\n",
    "\n",
    "• Provide a description of the collection process executed to build the dataset. Discuss the\n",
    "implications of the data collection method on the generated conclusions and insights.\n",
    "Note that you may need to look at relevant sources related to the dataset to acquire\n",
    "necessary information for this part of the project.\n",
    "\n",
    "• Describe the structure of the dataset file. <br>\n",
    "    o What does each row and column represent? <br>\n",
    "    o How many instances are there in the dataset? <br>\n",
    "    o How many features are there in the dataset? <br>\n",
    "    o If the dataset is composed of different files that you will combine in the succeeding\n",
    "steps, describe the structure and the contents of each file.\n",
    "\n",
    "• Discuss the features in each dataset file. What does each feature represent? All features,\n",
    "even those which are not used for the study, should be described to the reader. The\n",
    "purpose of each feature in the dataset should be clear to the reader of the notebook\n",
    "without having to go through an external link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Requirements\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [Numpy](https://numpy.org/)\n",
    "2. [Matplotlib](https://matplotlib.org/)\n",
    "3. [CSV](https://docs.python.org/3/library/csv.html)\n",
    "\n",
    "For this notebook, **numpy**, **matplotlib**, and **csv** must be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\cymon\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cymon\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\cymon\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\cymon\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A5vlL2jfDNoE",
    "outputId": "7b0fd08a-ac20-4c02-97f0-392001a32f0d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reading the Dataset\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "Here we will load the dataset using `csv`. We use the [`reader`](https://docs.python.org/3/library/csv.html) function to load the dataset. The path will have to be changed depending on the location of the file in your machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_in min/ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>That's What I Like (feat. Gucci Mane)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.964</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>134.071</td>\n",
       "      <td>234596.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Hitch a Ride</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.814</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>116.454</td>\n",
       "      <td>251733.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Raincoats</td>\n",
       "      <td>No Side to Fall In</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>147.681</td>\n",
       "      <td>109667.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deno</td>\n",
       "      <td>Lingo (feat. J.I &amp; Chunkz)</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.597</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>107.033</td>\n",
       "      <td>173968.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>Nobody Weird Like Me - Remastered</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.975</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>199.060</td>\n",
       "      <td>229960.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Artist Name                             Track Name  Popularity  \\\n",
       "0             Bruno Mars  That's What I Like (feat. Gucci Mane)        60.0   \n",
       "1                 Boston                           Hitch a Ride        54.0   \n",
       "2          The Raincoats                     No Side to Fall In        35.0   \n",
       "3                   Deno             Lingo (feat. J.I & Chunkz)        66.0   \n",
       "4  Red Hot Chili Peppers      Nobody Weird Like Me - Remastered        53.0   \n",
       "\n",
       "   danceability  energy   key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.854   0.564   1.0    -4.964     1       0.0485      0.017100   \n",
       "1         0.382   0.814   3.0    -7.230     1       0.0406      0.001100   \n",
       "2         0.434   0.614   6.0    -8.334     1       0.0525      0.486000   \n",
       "3         0.853   0.597  10.0    -6.528     0       0.0555      0.021200   \n",
       "4         0.167   0.975   2.0    -4.279     1       0.2160      0.000169   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  duration_in min/ms  \\\n",
       "0               NaN    0.0849   0.8990  134.071            234596.0   \n",
       "1          0.004010    0.1010   0.5690  116.454            251733.0   \n",
       "2          0.000196    0.3940   0.7870  147.681            109667.0   \n",
       "3               NaN    0.1220   0.5690  107.033            173968.0   \n",
       "4          0.016100    0.1720   0.0918  199.060            229960.0   \n",
       "\n",
       "   time_signature  Class  \n",
       "0               4      5  \n",
       "1               4     10  \n",
       "2               4      6  \n",
       "3               4      5  \n",
       "4               4     10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df = pd.read_csv('music.csv')\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now loaded in the ???.\n",
    "\n",
    "Show the contents of the..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis Questions\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [**`Question 4`**](#question-4): Distribution of Features: Plot histograms or kernel density plots for Valence, Tempo, Liveness, Loudness, Acousticness, and Energy to understand their distributions.\n",
    "2. [**`Question 5`**](#question-5): Class Distribution: Plot the distribution of the Class variable (target variable). Understand the balance between different classes.\n",
    "3. [**`Question 6`**](#question-6): Relationship Between Features and Class: Use scatter plots or box plots to visualize the relationship between each feature and the target Class variable Identify any patterns or clusters that may exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing and Cleaning\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cymon\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\cymon\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\\<indicate target task (i.e. classification or regression) here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "**`Music`** is a universal language, transcending cultures and time. It is a powerful art form that can evoke a wide range of emotions, from joy and excitement to sadness and reflection. Music can be used to express oneself, to connect with others, and to celebrate life. We are studying this dataset because it could be essential for studying music and developing new music technologies. In this notebook in particular, it will be used to train machine learning models to perform a variety of tasks. These models can then be used to create new products and services, such as personalized music streaming services and intelligent music assistants.\n",
    "\n",
    "The dataset is provided as a `.csv` file where it can be viewed in Excel and Notepad. \n",
    "\n",
    "This dataset contains 17,996 **rows** across 17 **columns**. Each row represents **1 song**, while columns represent **audio features**. The following are the columns in the dataset and their descriptions:\n",
    "\n",
    "| Column Name | Description |\n",
    "| --- | --- |\n",
    "| **`Artist Name`** | Name of artist |\n",
    "| **`Track Name`** | Name of song |\n",
    "| **`Popularity`** | A value between 0 and 100, calculated by an algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are |\n",
    "| **`danceability`** | Describes how suitable a track is for dancing; 0.0 is least danceable and 1.0 is most danceable |\n",
    "| **`energy`** | A measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity |\n",
    "| **`key`** | The key the track is in, integers map to pitches using standard [Pitch Class notation](https://en.wikipedia.org/wiki/Pitch_class); -1 if no key was detected |\n",
    "| **`loudness`** | The quality of a sound that is the primary psychological correlate of physical strength (amplitude), values are averaged across the entire track; in decibels (dB) |\n",
    "| **`mode`** | Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived; 1 is Major and 0 is Minor |\n",
    "| **`speechiness`** | The presence of spoken words in a track; >0.66 is probably made entirely of spoken words, 0.33-0.66 may contain both music and speech, <0.33 most likely represents music |\n",
    "| **`acousticness`** | A confidence measure from 0.0 to 1.0 of whether the track is acoustic |\n",
    "| **`instrumentalness`** | Predicts whether a track contains no vocals; >0.5 is intended to represent instrumental tracks |\n",
    "| **`liveness`** | Detects the presence of an audience in the recording; >0.8 provides strong likelihood that the track is live |\n",
    "| **`valence`** | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track; tracks with high valence sound more positive, and vice versa|\n",
    "| **`tempo`** | The overall estimated tempo of a track in beats per minute (BPM) |\n",
    "| **`duration_in min/ms`** | Duration in millisecond (ms) |\n",
    "| **`time_signature`** | A notational convention to specify how many beats are in each bar |\n",
    "| **`Class`** | corresponds to the genre of the track |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State a brief description of the dataset.\n",
    "\n",
    "• Provide a description of the collection process executed to build the dataset. Discuss the\n",
    "implications of the data collection method on the generated conclusions and insights.\n",
    "Note that you may need to look at relevant sources related to the dataset to acquire\n",
    "necessary information for this part of the project.\n",
    "\n",
    "• Describe the structure of the dataset file. <br>\n",
    "    o What does each row and column represent? <br>\n",
    "    o How many instances are there in the dataset? <br>\n",
    "    o How many features are there in the dataset? <br>\n",
    "    o If the dataset is composed of different files that you will combine in the succeeding\n",
    "steps, describe the structure and the contents of each file.\n",
    "\n",
    "• Discuss the features in each dataset file. What does each feature represent? All features,\n",
    "even those which are not used for the study, should be described to the reader. The\n",
    "purpose of each feature in the dataset should be clear to the reader of the notebook\n",
    "without having to go through an external link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Requirements\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [Numpy](https://numpy.org/)\n",
    "2. [Matplotlib](https://matplotlib.org/)\n",
    "3. [CSV](https://docs.python.org/3/library/csv.html)\n",
    "\n",
    "For this notebook, **numpy**, **matplotlib**, and **csv** must be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\cymon\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cymon\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Requirement already satisfied: pandas in c:\\users\\cymon\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cymon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A5vlL2jfDNoE",
    "outputId": "7b0fd08a-ac20-4c02-97f0-392001a32f0d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "Here we will load the dataset using `csv`. We use the [`reader`](https://docs.python.org/3/library/csv.html) function to load the dataset. The path will have to be changed depending on the location of the file in your machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('music.csv')\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now loaded in the ???.\n",
    "\n",
    "Show the contents of the..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis Questions\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [**`Question 4`**](#question-4): Distribution of Features: Plot histograms or kernel density plots for Valence, Tempo, Liveness, Loudness, Acousticness, and Energy to understand their distributions.\n",
    "2. [**`Question 5`**](#question-5): Class Distribution: Plot the distribution of the Class variable (target variable). Understand the balance between different classes.\n",
    "3. [**`Question 6`**](#question-6): Relationship Between Features and Class: Use scatter plots or box plots to visualize the relationship between each feature and the target Class variable Identify any patterns or clusters that may exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Cleaning\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can begin exploring the data, we must first clean the dataset. This is to prevent inconsistencies that may cause problems or errors during analysis.\n",
    "\n",
    "First, we will organize the dataset columns to make it easier to understand. Also, some columns are renamed for shorter accessibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin exploring our data, it is important to understand what are the characteristics of our features to help us make smart decisions to our pre-processing steps. It identifies which pre-processing techniques can be done so that exploratory data analysis and data modeeling is most accurate. Most importantly, this is done to prevent inconsistencies that may cause problems or errors during analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Renaming \n",
    "\n",
    "First, we will organize the dataset columns to make it easier to understand. Also, some columns are renamed for shorter accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'Artist Name': 'artist',\n",
    "    'Track Name': 'track',\n",
    "    'Popularity': 'popularity',\n",
    "    'danceability': 'dance',\n",
    "    'energy': 'energy',\n",
    "    'key': 'key',\n",
    "    'loudness': 'loudness',\n",
    "    'mode': 'mode',\n",
    "    'speechiness': 'speechiness',\n",
    "    'acousticness': 'acousticness',\n",
    "    'instrumentalness': 'instrumentalness',\n",
    "    'liveness': 'liveness',\n",
    "    'valence': 'valence',\n",
    "    'tempo': 'tempo',\n",
    "    'duration_in min/ms': 'duration',\n",
    "    'time_signature': 'time_signature',\n",
    "    'Class': 'class'\n",
    "}\n",
    "\n",
    "# Rename columns in the DataFrame\n",
    "music_df.rename(columns=column_mapping, inplace=True)\n",
    "print(music_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "We then check if there are any duplicated data in the dataset. We do this by calling the ``pandas.DataFrame.duplicated`` function. The function checks and returns the duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numDuplicates = music_df.duplicated().sum()\n",
    "\n",
    "print(f\"Number of duplicates in the dataset: {numDuplicates}\")\n",
    "\n",
    "# Display duplicated rows\n",
    "duplicated_rows_data = music_df[music_df.duplicated()]\n",
    "print(\"Duplicated rows:\")\n",
    "print(duplicated_rows_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As displayed above there are **``0 duplicates``** in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "Then, check which columns have **NaN or Null** values and **count** how many null values each column has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show nan_count per variable\n",
    "nan_counts = music_df.isna().sum()\n",
    "for feature, nan_count in nan_counts.items():\n",
    "    print(f\"{feature}: {nan_count}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=nan_counts.index, y=nan_counts.values, palette='viridis')\n",
    "plt.title('NaN Counts per Feature')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Number of NaN Values')\n",
    "plt.xticks(rotation=45, ha='right')  # Adjust rotation for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that `popularity`, `key`, and `instrumentalness` has a high count of NaN values. We can use imputation to replace the NaN values with a measure the mean of the column for the non-categorical features. As for categorical features, we will drop the rows as shown below. We will use `pandas.DataFrame.fillna` and `pandas.DataFrame.mean` for our regression values while `pandas.DataFrame.dropna` to drop rows with null categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill NaN for numerical features with mean\n",
    "numerical_features = ['popularity', 'dance', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "music_df[numerical_features] = music_df[numerical_features].fillna(music_df[numerical_features].mean())\n",
    "\n",
    "# Fill NaN for categorical features with a specific value (e.g., 'Unknown')\n",
    "categorical_features = ['artist', 'track', 'key', 'mode', 'time_signature', 'class']\n",
    "music_df_cleaned = music_df.dropna(subset=categorical_features)\n",
    "\n",
    "# Display NaN counts per feature\n",
    "nan_counts = music_df.isna().sum()\n",
    "for feature, nan_count in nan_counts.items():\n",
    "    print(f\"{feature}: {nan_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a graph of the amount of null data in each column for better visualization. As shown below, we can see that all of the columns now have 0 NaN values after performing imputation and dropping of rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for null data in each column\n",
    "null_data = music_df.isnull()\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=null_data.columns, y=null_data.sum(), palette='pastel')\n",
    "plt.title('Null Data Counts per Column')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Null Values')\n",
    "plt.xticks(rotation=45, ha='right')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_df = music_df.dropna(subset=['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for null data in each column\n",
    "null_data = music_df.isnull()\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=null_data.columns, y=null_data.sum(), palette='pastel')\n",
    "plt.title('Null Data Counts per Column')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Null Values')\n",
    "plt.xticks(rotation=45, ha='right')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Outliers\n",
    "\n",
    "Descriptive statistics provide a comprehensive overview of the numerical characteristics of each feature, offering insights into their central tendency (mean, median), dispersion (standard deviation), and range (min, max). Additionally, the identification of outliers is crucial to understanding potential anomalies that may influence the distribution and subsequently impact the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use `pandas.DataFrame.describe` to describe our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that some of the features namely, `energy`, `acousticness`, and `instrumentalness` have a min value of `0.000020`,`0.000000`, and `0.000001` respectively. We will eliminate instances with such small values in our dataset in an effort to reduce skewness that is heavily close to 0. However, this may significantly affect the size of our because these cover around 25% of our current size. Still, we opt to provide a higher accuracy even on a smaller dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_df_filtered = music_df[(music_df['energy'] >= 0.01) & (music_df['acousticness'] >= 0.01) & (music_df['instrumentalness'] >= 0.01)]\n",
    "music_df_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can use Boxplots from `seaborn` to identify possible outliers for the **numerical/continuous features**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_boxplot(data, numerical_features):\n",
    "    numeric_features = data[numerical_features].columns\n",
    "\n",
    "    num_features = len(numeric_features)\n",
    "    num_cols = 2  # You can adjust the number of columns as needed\n",
    "    num_rows = math.ceil(num_features / num_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(10, 2 * num_rows))\n",
    "    fig.suptitle('Boxplots of Numeric Features', y=1.02)\n",
    "\n",
    "    for idx, feature in enumerate(numeric_features):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        sns.boxplot(x=data[feature], ax=ax)\n",
    "        ax.set_title(f'Boxplot of {feature}')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_boxplot(music_df_filtered, numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that some of the features namely, `popularity`, `dance`, `loudness`, `speechiness`, `instrumentalness`, `liveness`, and `tempo` have an outstanding number of outliers way past the whiskers of the boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `Interquartile Range` to remove outliers. This technique sets up a boundary outside Quartile 1 (Q1) and Quartile 3 (Q3). To do this, a multiplier of `1.5` is used to the data of the IQR, and the result is subtracted to Q1, while is added to Q3. Any instances in the data that are more than these boundaries are considered as outliers. (3.2 - Identifying Outliers: IQR Method | STAT 200, n.d.).\n",
    "\n",
    "Using this will remove all the instances that have values below 25% and above 75% of the dataset based on two columns `loudness` and `tempo`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get the quantile values based on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outlier_features = ['popularity', 'dance', 'loudness', 'speechiness', 'instrumentalness', 'liveness', 'tempo']\n",
    "\n",
    "# Calculate the IQR for each feature\n",
    "Q1 = music_df_filtered[outlier_features].quantile(0.25)\n",
    "Q3 = music_df_filtered[outlier_features].quantile(0.75)\n",
    "\n",
    "print(\"Quantile 1: \", Q1)\n",
    "print(\"Quantile 1: \", Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we subtract Q3 from Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated, we will use the multiplier `1.5`, store this on variable `multiplier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a multiplier for IQR (e.g., 1.5)\n",
    "multiplier = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check for outliers using the logic of Interquartile Range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify outliers based on the IQR\n",
    "outliers = (music_df_filtered[outlier_features] < (Q1 - multiplier * IQR)) | (music_df_filtered[outlier_features] > (Q3 + multiplier * IQR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the outliers determined, we can now filter our dataset accordingly. Store the filtered dataset in `music_no_outliers_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame without outliers\n",
    "music_no_outliers_df = music_df_filtered[~outliers.any(axis=1)]\n",
    "\n",
    "# Display information about removed outliers\n",
    "print(\"Number of rows before removing outliers:\", music_df.shape[0])\n",
    "print(\"Number of rows after removing outliers:\", music_no_outliers_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_boxplot(music_no_outliers_df, numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_histogram(data, columns):\n",
    "    # Set up the figure and axes\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 8))\n",
    "\n",
    "    # Flatten the axes for easier iteration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Create histograms for each column using a for loop\n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i]\n",
    "        ax.hist(data[column], bins=20, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(f'{column} distribution')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_histogram(music_no_outliers_df, ['popularity', 'dance', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions above tells that each of the features are either positively or negatively skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_no_outliers_normalized = music_no_outliers_df.copy()\n",
    "music_no_outliers_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in ['energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness']:\n",
    "    # Determine the range\n",
    "    min_val = np.min(music_no_outliers_df[column])\n",
    "    max_val = np.max(music_no_outliers_df[column])\n",
    "\n",
    "    # Apply Min-Max Normalization\n",
    "    normalized_data = (music_no_outliers_df[column] - min_val) / (max_val - min_val)\n",
    "    music_no_outliers_normalized[column] = normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_histogram(music_no_outliers_normalized, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_no_outliers_normalized.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned all columns that will be used for this notebook. We can now begin the [Exploratory Data Analysis](#exploratory-data-analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Question 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MUSIC DATASET - STINTSY S14 PROJECT (FLEXBOMB)\n",
    "<a id='MUSIC_DATASET'></a>\n",
    "This notebook is an exploratory data analysis on the Music Dataset. The dataset will be explained, cleaned, and explored by the end of this notebook.\n",
    "\n",
    "| **`Table of Contents`** |\n",
    "| --- |\n",
    "| [The Dataset](#the-dataset) |\n",
    "| [List of Requirements](#List-of-Requirements) |\n",
    "| [Reading the Dataset](#reading-the-dataset) |\n",
    "| [Data Preprocessing and Cleaning](#Data-Preprocessing-and-Cleaning) |\n",
    "| [Exploratory Data Analysis](#exploratory-data-analysis) |\n",
    "| - [Question 1](#Question-1:-question) |\n",
    "\n",
    "<br>\n",
    "\n",
    "**`Authors`**: \n",
    "- Fausto, Lorane Bernadeth M. <br>\n",
    "- Nadela, Cymon <br>\n",
    "- Oliva, Irah <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "**`Music`** is a universal language, transcending cultures and time. It is a powerful art form that can evoke a wide range of emotions, from joy and excitement to sadness and reflection. Music can be used to express oneself, to connect with others, and to celebrate life. We are studying this dataset because it could be essential for studying music and developing new music technologies. In this notebook in particular, it will be used to train machine learning models to perform a variety of tasks. These models can then be used to create new products and services, such as personalized music streaming services and intelligent music assistants.\n",
    "\n",
    "The dataset is provided as a `.csv` file where it can be viewed in Excel and Notepad. \n",
    "\n",
    "This dataset contains 17,996 **rows** across 17 **columns**. Each row represents **1 song**, while columns represent **audio features**. The following are the columns in the dataset and their descriptions:\n",
    "\n",
    "| Column Name | Description |\n",
    "| --- | --- |\n",
    "| **`Artist Name`** | Name of artist |\n",
    "| **`Track Name`** | Name of song |\n",
    "| **`Popularity`** | A value between 0 and 100, calculated by an algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are |\n",
    "| **`danceability`** | Describes how suitable a track is for dancing; 0.0 is least danceable and 1.0 is most danceable |\n",
    "| **`energy`** | A measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity |\n",
    "| **`key`** | The key the track is in, integers map to pitches using standard [Pitch Class notation](https://en.wikipedia.org/wiki/Pitch_class); -1 if no key was detected |\n",
    "| **`loudness`** | The quality of a sound that is the primary psychological correlate of physical strength (amplitude), values are averaged across the entire track; in decibels (dB) |\n",
    "| **`mode`** | Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived; 1 is Major and 0 is Minor |\n",
    "| **`speechiness`** | The presence of spoken words in a track; >0.66 is probably made entirely of spoken words, 0.33-0.66 may contain both music and speech, <0.33 most likely represents music |\n",
    "| **`acousticness`** | A confidence measure from 0.0 to 1.0 of whether the track is acoustic |\n",
    "| **`instrumentalness`** | Predicts whether a track contains no vocals; >0.5 is intended to represent instrumental tracks |\n",
    "| **`liveness`** | Detects the presence of an audience in the recording; >0.8 provides strong likelihood that the track is live |\n",
    "| **`valence`** | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track; tracks with high valence sound more positive, and vice versa|\n",
    "| **`tempo`** | The overall estimated tempo of a track in beats per minute (BPM) |\n",
    "| **`duration_in min/ms`** | Duration in millisecond (ms) |\n",
    "| **`time_signature`** | A notational convention to specify how many beats are in each bar |\n",
    "| **`Class`** | corresponds to the genre of the track |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Requirements\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [Numpy](https://numpy.org/)\n",
    "2. [Matplotlib](https://matplotlib.org/)\n",
    "3. [CSV](https://docs.python.org/3/library/csv.html)\n",
    "\n",
    "For this notebook, **numpy**, **matplotlib**, and **csv** must be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A5vlL2jfDNoE",
    "outputId": "7b0fd08a-ac20-4c02-97f0-392001a32f0d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "Here we will load the dataset using `csv`. We use the [`reader`](https://docs.python.org/3/library/csv.html) function to load the dataset. The path will have to be changed depending on the location of the file in your machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('music.csv')\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing and Cleaning\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can begin exploring the data, we must first clean the dataset. This is to prevent inconsistencies that may cause problems or errors during analysis.\n",
    "\n",
    "First, we will organize the dataset columns to make it easier to understand. Also, some columns are renamed for shorter accessibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin exploring our data, it is important to understand what are the characteristics of our features to help us make smart decisions to our pre-processing steps. It identifies which pre-processing techniques can be done so that exploratory data analysis and data modeeling is most accurate. Most importantly, this is done to prevent inconsistencies that may cause problems or errors during analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Renaming \n",
    "\n",
    "First, we will organize the dataset columns to make it easier to understand. Also, some columns are renamed for shorter accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'Artist Name': 'artist',\n",
    "    'Track Name': 'track',\n",
    "    'Popularity': 'popularity',\n",
    "    'danceability': 'dance',\n",
    "    'energy': 'energy',\n",
    "    'key': 'key',\n",
    "    'loudness': 'loudness',\n",
    "    'mode': 'mode',\n",
    "    'speechiness': 'speechiness',\n",
    "    'acousticness': 'acousticness',\n",
    "    'instrumentalness': 'instrumentalness',\n",
    "    'liveness': 'liveness',\n",
    "    'valence': 'valence',\n",
    "    'tempo': 'tempo',\n",
    "    'duration_in min/ms': 'duration',\n",
    "    'time_signature': 'time_signature',\n",
    "    'Class': 'class'\n",
    "}\n",
    "\n",
    "# Rename columns in the DataFrame\n",
    "music_df.rename(columns=column_mapping, inplace=True)\n",
    "print(music_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "We then check if there are any duplicated data in the dataset. We do this by calling the ``pandas.DataFrame.duplicated`` function. The function checks and returns the duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numDuplicates = music_df.duplicated().sum()\n",
    "\n",
    "print(f\"Number of duplicates in the dataset: {numDuplicates}\")\n",
    "\n",
    "# Display duplicated rows\n",
    "duplicated_rows_data = music_df[music_df.duplicated()]\n",
    "print(\"Duplicated rows:\")\n",
    "print(duplicated_rows_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As displayed above there are **``0 duplicates``** in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "Then, check which columns have **NaN or Null** values and **count** how many null values each column has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show nan_count per variable\n",
    "nan_counts = music_df.isna().sum()\n",
    "for feature, nan_count in nan_counts.items():\n",
    "    print(f\"{feature}: {nan_count}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=nan_counts.index, y=nan_counts.values, palette='viridis')\n",
    "plt.title('NaN Counts per Feature')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Number of NaN Values')\n",
    "plt.xticks(rotation=45, ha='right')  # Adjust rotation for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that `popularity`, `key`, and `instrumentalness` has a high count of NaN values. We can use imputation to replace the NaN values with a measure the mean of the column for the non-categorical features. As for categorical features, we will drop the rows as shown below. We will use `pandas.DataFrame.fillna` and `pandas.DataFrame.mean` for our regression values while `pandas.DataFrame.dropna` to drop rows with null categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill NaN for numerical features with mean\n",
    "numerical_features = ['popularity', 'dance', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "music_df[numerical_features] = music_df[numerical_features].fillna(music_df[numerical_features].mean())\n",
    "\n",
    "# Fill NaN for categorical features with a specific value (e.g., 'Unknown')\n",
    "categorical_features = ['artist', 'track', 'key', 'mode', 'time_signature', 'class']\n",
    "music_df_cleaned = music_df.dropna(subset=categorical_features)\n",
    "\n",
    "# Display NaN counts per feature\n",
    "nan_counts = music_df.isna().sum()\n",
    "for feature, nan_count in nan_counts.items():\n",
    "    print(f\"{feature}: {nan_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a graph of the amount of null data in each column for better visualization. As shown below, we can see that all of the columns now have 0 NaN values after performing imputation and dropping of rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for null data in each column\n",
    "null_data = music_df.isnull()\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=null_data.columns, y=null_data.sum(), palette='pastel')\n",
    "plt.title('Null Data Counts per Column')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Null Values')\n",
    "plt.xticks(rotation=45, ha='right')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_df = music_df.dropna(subset=['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for null data in each column\n",
    "null_data = music_df.isnull()\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=null_data.columns, y=null_data.sum(), palette='pastel')\n",
    "plt.title('Null Data Counts per Column')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Null Values')\n",
    "plt.xticks(rotation=45, ha='right')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Outliers\n",
    "\n",
    "Descriptive statistics provide a comprehensive overview of the numerical characteristics of each feature, offering insights into their central tendency (mean, median), dispersion (standard deviation), and range (min, max). Additionally, the identification of outliers is crucial to understanding potential anomalies that may influence the distribution and subsequently impact the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use `pandas.DataFrame.describe` to describe our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that some of the features namely, `energy`, `acousticness`, and `instrumentalness` have a min value of `0.000020`,`0.000000`, and `0.000001` respectively. We will eliminate instances with such small values in our dataset in an effort to reduce skewness that is heavily close to 0. However, this may significantly affect the size of our because these cover around 25% of our current size. Still, we opt to provide a higher accuracy even on a smaller dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_df_filtered = music_df[(music_df['energy'] >= 0.01) & (music_df['acousticness'] >= 0.01) & (music_df['instrumentalness'] >= 0.01)]\n",
    "music_df_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can use Boxplots from `seaborn` to identify possible outliers for the **numerical/continuous features**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_boxplot(data, numerical_features):\n",
    "    numeric_features = data[numerical_features].columns\n",
    "\n",
    "    num_features = len(numeric_features)\n",
    "    num_cols = 2  # You can adjust the number of columns as needed\n",
    "    num_rows = math.ceil(num_features / num_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(10, 2 * num_rows))\n",
    "    fig.suptitle('Boxplots of Numeric Features', y=1.02)\n",
    "\n",
    "    for idx, feature in enumerate(numeric_features):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        sns.boxplot(x=data[feature], ax=ax)\n",
    "        ax.set_title(f'Boxplot of {feature}')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_boxplot(music_df_filtered, numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that some of the features namely, `popularity`, `dance`, `loudness`, `speechiness`, `instrumentalness`, `liveness`, and `tempo` have an outstanding number of outliers way past the whiskers of the boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `Interquartile Range` to remove outliers. This technique sets up a boundary outside Quartile 1 (Q1) and Quartile 3 (Q3). To do this, a multiplier of `1.5` is used to the data of the IQR, and the result is subtracted to Q1, while is added to Q3. Any instances in the data that are more than these boundaries are considered as outliers. (3.2 - Identifying Outliers: IQR Method | STAT 200, n.d.).\n",
    "\n",
    "Using this will remove all the instances that have values below 25% and above 75% of the dataset based columns.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get the quantile values based on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outlier_features = ['popularity', 'dance', 'loudness', 'speechiness', 'instrumentalness', 'liveness', 'tempo']\n",
    "\n",
    "# Calculate the IQR for each feature\n",
    "Q1 = music_df_filtered[outlier_features].quantile(0.25)\n",
    "Q3 = music_df_filtered[outlier_features].quantile(0.75)\n",
    "\n",
    "print(\"Quantile 1: \", Q1)\n",
    "print(\"Quantile 1: \", Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we subtract Q3 from Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated, we will use the multiplier `1.5`, store this on variable `multiplier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a multiplier for IQR (e.g., 1.5)\n",
    "multiplier = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check for outliers using the logic of Interquartile Range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify outliers based on the IQR\n",
    "outliers = (music_df_filtered[outlier_features] < (Q1 - multiplier * IQR)) | (music_df_filtered[outlier_features] > (Q3 + multiplier * IQR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the outliers determined, we can now filter our dataset accordingly. Store the filtered dataset in `music_no_outliers_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame without outliers\n",
    "music_no_outliers_df = music_df_filtered[~outliers.any(axis=1)]\n",
    "\n",
    "# Display information about removed outliers\n",
    "print(\"Number of rows before removing outliers:\", music_df.shape[0])\n",
    "print(\"Number of rows after removing outliers:\", music_no_outliers_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_boxplot(music_no_outliers_df, numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the boxplots above, it seems that there are still outliers even if we remove some of them using Interquartile Range. We can visualize `music_no_outliers_df` through a histogram for us to understand how each of the features are characterized under the normal distribution. To do this we will use the module `matplotlib.pyplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_histogram(data, columns):\n",
    "    # Set up the figure and axes\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 8))\n",
    "\n",
    "    # Flatten the axes for easier iteration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Create histograms for each column using a for loop\n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i]\n",
    "        ax.hist(data[column], bins=20, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(f'{column} distribution')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_histogram(music_no_outliers_df, ['popularity', 'dance', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the features `speechiness`, `acousticness`, `instrumentalness`, and `liveness` are negatively skewed, with more instances having a value that is closer to 0. Features `dance`, `energy`, `and loudness` are positively skewed, on the other hand. While the rest are closer to the normal distribution. Based on the outliers and histograms, it seems that the outliers remained even after the outlier removal step does contribute to the overall meaning of the data. For example, `liveness` infers that the songs tend to decrease in frequency as the value of being lively increases from zero (0) to one (1).\n",
    "\n",
    "We will try to normalize the values on these features using Min-Max Scaling. This algoritm scales the data according to the lowest possible and highest possible values, so that it is focused (*scaled*) while maintaining its relative position (Loukas, 2023). First, let's store a copy of `music_no_outliers_df` to a variable called `music_no_outliers_normalized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_no_outliers_normalized = music_no_outliers_df.copy()\n",
    "music_no_outliers_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for each column below, normalize each of the data and store back to their respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in ['energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness']:\n",
    "    # Determine the range\n",
    "    min_val = np.min(music_no_outliers_df[column])\n",
    "    max_val = np.max(music_no_outliers_df[column])\n",
    "\n",
    "    # Apply Min-Max Normalization\n",
    "    normalized_data = (music_no_outliers_df[column] - min_val) / (max_val - min_val)\n",
    "    music_no_outliers_normalized[column] = normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display the histogram of the normalized data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_histogram(music_no_outliers_normalized, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_no_outliers_normalized.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the features `speechiness`, `acousticness`, `instrumentalness`, and `liveness` are still negatively skewed and the normalization has failed. This may be due to where the values of the instanes lie in the data. Looking at the description of `music_no_outliers_normalized` above, it seems that 25% of the data based on these features are below 0.07 which is relatively small compared to the max value of 1.00. Because of this, it may be best to retain the data as is after the normalization attempt so that we can have a better how these features are related in the next section of our notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned all columns that will be used for this notebook. We can now begin the [Exploratory Data Analysis](#exploratory-data-analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis Questions\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [**`Question 4`**](#question-4): Distribution of Features: Plot histograms or kernel density plots for Valence, Tempo, Liveness, Loudness, Acousticness, and Energy to understand their distributions.\n",
    "2. [**`Question 5`**](#question-5): Class Distribution: Plot the distribution of the Class variable (target variable). Understand the balance between different classes.\n",
    "3. [**`Question 6`**](#question-6): Relationship Between Features and Class: Use scatter plots or box plots to visualize the relationship between each feature and the target Class variable Identify any patterns or clusters that may exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation_matrix = music_df[selected_features + [target_variable]].corr()\n",
    "correlation_matrix = music_df.select_dtypes(include='number').corr()\n",
    "\n",
    "# Display correlation coefficients\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EDA Question 1 Results\n",
    "This shows the relationship between 13 different audio features, including popularity, dance, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration, time signature, and class.\n",
    "\n",
    "The correlation values range from -1 to 1, with 1 indicating a perfect positive correlation, -1 indicating a perfect negative correlation, and 0 indicating no correlation.\n",
    "\n",
    "**Positive correlations**\n",
    "\n",
    "1. `Popularity` is positively correlated with `dance`, `energy`, and `loudness`. This suggests that more popular songs tend to be more danceable, energetic, and louder.\n",
    "2. `Dance` is positively correlated with `energy`, `loudness`, and `valence`. This suggests that danceable songs tend to be more energetic, louder, and more positive.\n",
    "3. `Energy` is positively correlated with `loudness` and `valence`. This suggests that energetic songs tend to be louder and more positive.\n",
    "4. `Speechiness` is positively correlated with `tempo`. This suggests that songs with more speech tend to have a faster tempo.\n",
    "5. `Acousticness` is positively correlated with `time signature`. This suggests that acoustic songs tend to have a more regular time signature.\n",
    "\n",
    "**Negative correlations**\n",
    "\n",
    "1. `Popularity` is negatively correlated with `acousticness`. This suggests that more popular songs tend to be less acoustic.\n",
    "2. `Dance` is negatively correlated with `speechiness` and `acousticness`. This suggests that danceable songs tend to have less speech and are less acoustic.\n",
    "3. `Energy` is negatively correlated with `acousticness`. This suggests that energetic songs tend to be less acoustic.\n",
    "4. `Instrumentalness` is negatively correlated with `valence`. This suggests that instrumental songs tend to be less positive.\n",
    "5. `Liveness` is negatively correlated with `acousticness`. This suggests that livelier songs tend to be less acoustic.\n",
    "6. `Tempo` is negatively correlated with `acousticness` and `duration`. This suggests that faster songs tend to be less acoustic and shorter.\n",
    "7. `Duration` is negatively correlated with `class`. This suggests that longer songs are less likely to be classified as a particular genre.\n",
    "\n",
    "Overall, the correlation heatmap provides insights into the relationships between different audio features. For example, we can see that more popular songs tend to be more danceable, energetic, and louder, while acoustic songs tend to be less popular, less danceable, and more mellow.\n",
    "\n",
    "To also gain insights for our Machine Learning, we provided insights for `mode` being our target variable.\n",
    "\n",
    "1. `Mode` is positively correlated with `key`, `loudness`, `speechiness`, `acousticness`, `instrumentalness`, `liveness`, `valence`, `tempo`, and `duration`. This means that songs in **major mode** tend to be *more popular, danceable, energetic, loud, speechy, acoustic, instrumental, live, positive, fast, and long.*\n",
    "\n",
    "2. `Mode` is negatively correlated with `popularity`, `danceability`, `energy`, and `valence`. This means that songs in **minor mode** tend to be *less popular, danceable, energetic, and positive.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What is the distribution of *`mode`*?\n",
    "\n",
    "Here, we will compare the number of *tracks* for each *mode*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_modeCount_df = music_no_outliers_normalized['mode'].value_counts()\n",
    "print(music_modeCount_df)\n",
    "\n",
    "music_modeCount_df.plot.bar(figsize=(6,4)).invert_xaxis()\n",
    "plt.xlabel('Mode')\n",
    "plt.ylabel('Number of Tracks')\n",
    "plt.title('Number of Tracks for each Mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Question 2 Results\n",
    "\n",
    "We can see that the dataset has more tracks in the major (1) mode, than in the minor (0) mode. There are 2467 tracks in the major (1) mode while minor (0) mode has 1426 tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: What is the distribution of the feature `class`?\n",
    "\n",
    "Here, we will compare the number of *tracks* for each *class*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.countplot(x='class', data=music_no_outliers_normalized, order=music_no_outliers_normalized['class'].value_counts(ascending=True).index)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Distribution of Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Tracks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Question 3 Results\n",
    "\n",
    "We can see that the lowest track count is 38 for class 7 while the highest has 970 tracks for class 10. Although, class 9 has 962 tracks which is coming at a close second. This means that most of the tracks in the dataset are at class 9 & 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: What is the distribution of the `mode` for each `class`?\n",
    "\n",
    "Here, we will compare the number of *modes* for each *class*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.crosstab(music_no_outliers_normalized['class'], music_no_outliers_normalized['mode']).plot(kind='bar', stacked=True)\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.bar_label(ax.containers[1])\n",
    "\n",
    "plt.title('Class Distribution by Mode')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Tracks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EDA Question 4 Results\n",
    "\n",
    "We can see that there is a different mode distribution for each class. \n",
    "\n",
    "| Class | Mode 0 | Mode 1 | Total |\n",
    "| --- | --- | --- | --- |\n",
    "| 0 | 52 | 168 | 220 |\n",
    "| 1 | 79 | 175 | 254 |\n",
    "| 2 | 104 | 208 | 312 |\n",
    "| 3 | 38 | 77 | 115 |\n",
    "| 4 | 11 | 171 | 182 |\n",
    "| 5 | 85 | 105 | 190 |\n",
    "| 6 | 202 | 368 | 570 |\n",
    "| 7 | 17 | 21 | 38 |\n",
    "| 8 | 38 | 42 | 80 |\n",
    "| 9 | 455 | 507 | 962 |\n",
    "| 10 | 345 | 625 | 970 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = music_no_outliers_normalized.select_dtypes(include='number')\n",
    "X.drop(['mode', 'class'], axis=1, inplace=True)\n",
    "y = music_no_outliers_normalized['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "Logistic Regression \n",
    "Let's instantiate an `SGDClassifier` object and set the following hyperparameters:\n",
    "- Loss function: 'log_loss'\n",
    "- Initial learning rate: 0.001\n",
    "- Maximum iterations: 200\n",
    "- Learning rate: 'constant'\n",
    "- Random state: 1\n",
    "- Verbose: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log_loss', \n",
    "                      eta0=0.001, \n",
    "                      max_iter=200, \n",
    "                      learning_rate='constant', \n",
    "                      random_state=1, \n",
    "                      verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the training data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_train)\n",
    "num_correct = np.count_nonzero((y_train==predictions))\n",
    "print(num_correct)\n",
    "accuracy = num_correct/len(y_train)\n",
    "print(\"Accuracy :\", accuracy * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, compare the results with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "num_correct = np.count_nonzero((y_test==predictions))\n",
    "print(num_correct)\n",
    "accuracy = num_correct/len(y_test)\n",
    "print(\"Accuracy :\", accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pd.DataFrame(model.predict_proba(X_test), columns=['y = 0', 'y = 1'])\n",
    "prob['actual'] = y_test.values\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune hyperparameters for our `SGDClassifier`, we can used  grid search. Scikit-learn provides the `GridSearchCV` classes for this purpose.\n",
    "\n",
    "Set our Pipeline that includes a standard scaler and the `SGDClassifier`\n",
    "We can set the parameter grid as a parameter for our `GridSearchCV` as such: \n",
    "> 'classifier__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0] <br>\n",
    "> 'classifier__max_iter': [100, 200, 300]<br>\n",
    "> 'classifier__eta0': [0.001, 0.01, 0.1]<br>\n",
    "\n",
    "We can Instantiate the `GridSearchCV` with our made pipeline, param_grid, cross validation = 5, scoring = accuracy, and verbose = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the pipeline with a standard scaler and SGDClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SGDClassifier(loss='log_loss', random_state=1, verbose=1))\n",
    "])\n",
    "\n",
    "# Define the hyperparameters \n",
    "param_grid = {\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "    'classifier__max_iter': [100, 200, 300],\n",
    "    'classifier__eta0': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "accuracy_test = best_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Test Accuracy with Best Model: {accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the grid search, we can now locate the best parameters for our Logistic regression.\n",
    "\n",
    "- Best Parameters: {'classifier__alpha': 0.01, 'classifier__eta0': 0.001, 'classifier__max_iter': 100}\n",
    "- Test Accuracy with Best Model: 0.6410844629822732\n",
    "\n",
    "We can finally select `best_model` SGDClassifier from above that contains the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = SGDClassifier(alpha=best_params['classifier__alpha'],\n",
    "                            max_iter=best_params['classifier__max_iter'],\n",
    "                            eta0=best_params['classifier__eta0'],\n",
    "                            loss='log_loss',\n",
    "                            random_state=1,\n",
    "                            verbose=1)\n",
    "\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accuracy = best_model.score(X_train, y_train)\n",
    "print(f\"Final Model Accuracy on Train Set: {final_accuracy}\")\n",
    "\n",
    "final_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Final Model Accuracy on Test Set: {final_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Logistic Regression Result:\n",
    "| Description | Without Tuning Hyperparameter | Tuned Hyperparameter\n",
    "| --- | --- | --- |\n",
    "| Epochs after Converge | `13` | `100` |\n",
    "| Average Loss at Converge | `3.950169` | `0.839764` |\n",
    "| Accuracy of the Model with X_train | `40.73%` | `63.82%` |\n",
    "| Accuracy of the Model with X_test | `43.40%` | `62.33%` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.001, 0.0001, 0.5],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter': [500, 1000, 2000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(MLPClassifier(random_state=42, hidden_layer_sizes=(50, 50, 50)), grid, cv = 5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"best parameters of the model: \", clf.best_params_)\n",
    "print(\"best score of the model: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = np.count_nonzero((y_train==predictions))/len(y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = np.count_nonzero((y_test==predictions))/len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "A **`random forest machine learning model`** is an ensemble model that makes use of multiple decision trees trained through bagging. It takes multiple decision tree classifier models and trains all models on bootstrapped data which is sampled from the training data without replacement because each decision tree is independent from each other. Each tree can be trained in parallel with the bootstrapped data. This should work well for our data because each tree can learn very specific features unique to each seed in the dataset that make it a specific category. To reduce overfitting, bagging and random partitions are used to increase the model's ability to generalize on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "predictions_train = rf_classifier.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, predictions_train)\n",
    "\n",
    "print(f\"Accuracy on training data: {accuracy_train}\")\n",
    "print(f\"Accuracy on test data: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 71.43% accuracy on the test data without hyperparameter tuning, and 100% accuracy on the training data. Random forests naturally get very high accuracies on the training set, which means it is not a cause for concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "We will be using *random search* to tune the hyperparameters of the random forest. The hyperparameter values are randomized at each interation within a specified range.\n",
    "\n",
    "- `n_estimators`: This is the total amount of decision trees used in the random forest, initially set to 100. The most frequent label generated by all the trees is the final label given by the ensemble model. \n",
    "- `max_depth`: The maximum depth all the trees are limited to, which can help reduce overfitting on training data. This is initially set to None.\n",
    "- `max_features`: Set to 'sqrt'. The total amount of features to consider to consider at each split of all trees.\n",
    "- `min_samples_split`: Set to 2. The minimum amount of data points that are needed to split a decision node. A higher value will prevent the model from making splits that are too specific to certain data points, or noise.\n",
    "- `min_samples_leaf`: Set to 1. The minimum number of samples a leaf node can have, increasing this can also reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(100,300),\n",
    "              'max_depth': randint(1,30),\n",
    "                'max_features': randint(1,5),\n",
    "               'min_samples_split': randint (2, 10),\n",
    "               'min_samples_leaf': randint(1, 5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search will run for 10 iterations using accuracy as the main evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "for i in range(len(random_search.cv_results_['params'])):\n",
    "    print(f\"Iteration {i + 1}:\")\n",
    "    print(\"Hyperparameters:\", random_search.cv_results_['params'][i])\n",
    "    print(\"Mean Test Score (Accuracy):\", random_search.cv_results_['mean_test_score'][i])\n",
    "    print('----------------------------------')\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "predictions = best_rf.predict(X_test)\n",
    "predictions_train = best_rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predictions)\n",
    "\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a precision 0.71 for both classes, which means the model is not better at predicting true positives for one class compared to the other. It has an overall accuracy of 71%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best model hyperparameters:\", random_search.best_params_)\n",
    "print(\"Accuracy of best model on test set: \", accuracy_score(predictions, y_test))\n",
    "print(\"Accuracy of best model on training set: \", accuracy_score(predictions_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 - Identifying outliers: IQR Method | STAT 200. (n.d.). PennState: Statistics Online Courses. https://online.stat.psu.edu/stat200/lesson/3/3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priyanka, P. (2023, September 5). Audio Normalization - Poudel priyanka - Medium. Medium. https://medium.com/@poudelnipriyanka/audio-normalization-9dbcedfefcc0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnolia International Ltd. (n.d.). TC Electronic | Loudness explained. https://www.tcelectronic.com/de/loudness-explained.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MasterClass. (n.d.). Beats per Minute explained: How to find a song’s BPM - 2023 - MasterClass. https://www.masterclass.com/articles/how-to-find-the-bpm-of-a-song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "**`Music`** is a universal language, transcending cultures and time. It is a powerful art form that can evoke a wide range of emotions, from joy and excitement to sadness and reflection. Music can be used to express oneself, to connect with others, and to celebrate life. We are studying this dataset because it could be essential for studying music and developing new music technologies. In this notebook in particular, it will be used to train machine learning models to perform a variety of tasks. These models can then be used to create new products and services, such as personalized music streaming services and intelligent music assistants.\n",
    "\n",
    "The dataset is provided as a `.csv` file where it can be viewed in Excel and Notepad. \n",
    "\n",
    "This dataset contains 17,996 **rows** across 17 **columns**. Each row represents **1 song**, while columns represent **audio features**. The following are the columns in the dataset and their descriptions:\n",
    "\n",
    "| Column Name | Description |\n",
    "| --- | --- |\n",
    "| **`Artist Name`** | Name of artist |\n",
    "| **`Track Name`** | Name of song |\n",
    "| **`Popularity`** | A value between 0 and 100, calculated by an algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are |\n",
    "| **`danceability`** | Describes how suitable a track is for dancing; 0.0 is least danceable and 1.0 is most danceable |\n",
    "| **`energy`** | A measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity |\n",
    "| **`key`** | The key the track is in, integers map to pitches using standard [Pitch Class notation](https://en.wikipedia.org/wiki/Pitch_class); -1 if no key was detected |\n",
    "| **`loudness`** | The quality of a sound that is the primary psychological correlate of physical strength (amplitude), values are averaged across the entire track; in decibels (dB) |\n",
    "| **`mode`** | Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived; 1 is Major and 0 is Minor |\n",
    "| **`speechiness`** | The presence of spoken words in a track; >0.66 is probably made entirely of spoken words, 0.33-0.66 may contain both music and speech, <0.33 most likely represents music |\n",
    "| **`acousticness`** | A confidence measure from 0.0 to 1.0 of whether the track is acoustic |\n",
    "| **`instrumentalness`** | Predicts whether a track contains no vocals; >0.5 is intended to represent instrumental tracks |\n",
    "| **`liveness`** | Detects the presence of an audience in the recording; >0.8 provides strong likelihood that the track is live |\n",
    "| **`valence`** | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track; tracks with high valence sound more positive, and vice versa|\n",
    "| **`tempo`** | The overall estimated tempo of a track in beats per minute (BPM) |\n",
    "| **`duration_in min/ms`** | Duration in millisecond (ms) |\n",
    "| **`time_signature`** | A notational convention to specify how many beats are in each bar |\n",
    "| **`Class`** | corresponds to the genre of the track |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State a brief description of the dataset.\n",
    "\n",
    "• Provide a description of the collection process executed to build the dataset. Discuss the\n",
    "implications of the data collection method on the generated conclusions and insights.\n",
    "Note that you may need to look at relevant sources related to the dataset to acquire\n",
    "necessary information for this part of the project.\n",
    "\n",
    "• Describe the structure of the dataset file. <br>\n",
    "    o What does each row and column represent? <br>\n",
    "    o How many instances are there in the dataset? <br>\n",
    "    o How many features are there in the dataset? <br>\n",
    "    o If the dataset is composed of different files that you will combine in the succeeding\n",
    "steps, describe the structure and the contents of each file.\n",
    "\n",
    "• Discuss the features in each dataset file. What does each feature represent? All features,\n",
    "even those which are not used for the study, should be described to the reader. The\n",
    "purpose of each feature in the dataset should be clear to the reader of the notebook\n",
    "without having to go through an external link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Requirements\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [Numpy](https://numpy.org/)\n",
    "2. [Matplotlib](https://matplotlib.org/)\n",
    "3. [CSV](https://docs.python.org/3/library/csv.html)\n",
    "\n",
    "For this notebook, **numpy**, **matplotlib**, and **csv** must be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A5vlL2jfDNoE",
    "outputId": "7b0fd08a-ac20-4c02-97f0-392001a32f0d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "Here we will load the dataset using `csv`. We use the [`reader`](https://docs.python.org/3/library/csv.html) function to load the dataset. The path will have to be changed depending on the location of the file in your machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('music.csv')\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now loaded in the ???.\n",
    "\n",
    "Show the contents of the..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis Questions\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --\n",
    "\n",
    "1. [**`Question 4`**](#question-4): Distribution of Features: Plot histograms or kernel density plots for Valence, Tempo, Liveness, Loudness, Acousticness, and Energy to understand their distributions.\n",
    "2. [**`Question 5`**](#question-5): Class Distribution: Plot the distribution of the Class variable (target variable). Understand the balance between different classes.\n",
    "3. [**`Question 6`**](#question-6): Relationship Between Features and Class: Use scatter plots or box plots to visualize the relationship between each feature and the target Class variable Identify any patterns or clusters that may exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Preprocessing and Cleaning\n",
    "\n",
    "-- [Return to Table of Contents](#music-dataset---stintsy-s14-project-(flexbomb)) --"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1 - Jupyter Notebook and Python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "35ed6aa12a0d6ba18c9d471f8c51327fdbfc13293fb971f148297e9497ae5ae2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
